{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Computaci\u00f3n en GPUs con (py)CUDA\n",
      "\n",
      "##Libreta 9. Introducci\u00f3n a pyCUDA\n",
      "\n",
      "\n",
      "###Tabla de Contenidos:\n",
      "\n",
      "1. Difusi\u00f3n en 2D\n",
      "\n",
      "2. Comparaci\u00f3n entre GPU, CPU (con C) y Python\n",
      "\n",
      "3. \n",
      "\n",
      "4. Ejercicios\n",
      "\n",
      "5. Material adicional"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###1. pyCUDA\n",
      "Las libretas anteriores nos han permitido comparar de manera muy b\u00e1sica los tiempos de ejecuci\u00f3n del CPU (usando C y Python) y el GPU (usando CUDA C y puCUDA), y observamos que pyCUDA tiene un desempe\u00f1o incluso mejor que CUDA C cuando se aprovechan las librerias optimizadas de NumPy junto con el uso del GPU via pyCUDA.\n",
      "\n",
      "Dada la ganancia que se puede obtener al usar Python junto con el GPU, desarrollaremos nuestras aplicaciones en este ambiente de programaci\u00f3n. Mas adelante introduciremos otras herramientas que permiten obtener codigo compilado incluso mas eficiente.\n",
      "\n",
      "En esta libreta vamos a resolver otro problema que es altamente paralelizable y comenzaremos con nuestra aventura al mundo de resolver aplicaciones usando GPUs (y pyCUDA!).\n",
      "\n",
      "modificar el c\u00f3digo de pyCUDA de la Libreta 8 para reducir el numero de instrucciones en lo referente al modelo de programaci\u00f3n de CUDA, con ayuda de algunos m\u00e9todos que tiene pyCUDA, con lo que se hace mas transparente el uso del GPU.\n",
      "\n",
      "###2. pyCUDA\n",
      "Volvemos al modelo b\u00e1sico de programaci\u00f3n de CUDA con algunos problemas adicionales usando resolviendolos usando pyCUDA, para conocer algunos de los distintos comandos que provee este marco de trabajo.\n",
      "\n",
      "Primero llamaremos las librer\u00edas necesarias para invocar pyCUDA:\n",
      "\n",
      "    import pycuda.driver as cuda\n",
      "    import pycuda.autoinit\n",
      "    from pycuda.compiler import SourceModule\n",
      "    \n",
      "\n",
      "####2.1 Negando cada elemento de un arreglo\n",
      "El primer ejemplo consiste en cambiar el signo, negar, cad elemento de un arreglo, es decir si $$a=[a_1, \\cdots, a_n]$$ queremos obtener $b = -1a = [-a_1, \\cdots, -a_n].$$\n",
      "\n",
      "Este ejercicion es una operaci\u00f3n similar a las presentadas en las primeras libretas, y esperamos que el desempe\u00f1o sea mucho mejor usando el CPU. Sin embargo en esta libreta queremos exponer distintos modos de utilizar el GPU usando pyCUDA y no nos preocupa, por el momento, el desempe\u00f1o o tiempo de ejecuci\u00f3n.\n",
      "\n",
      "Primero importamos las librerias necesarias para poder usar pyCUDA:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####2.2 Primeros pasos\n",
      "El modelo de programaci\u00f3n de CUDA seguir\u00eda los siguientes pasos:\n",
      "\n",
      "* Declarar el arreglo en el _host_\n",
      "* Declarar el arreglo en el GPU\n",
      "* Copiar arreglo del _host_ al GPU\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = numpy.random.randn(4,4)\n",
      "\n",
      "a = a.astype(numpy.float32)\n",
      "\n",
      "a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
      "\n",
      "cuda.memcpy_htod(a_gpu, a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Ejecutar el kernel en el GPU:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod = SourceModule(\"\"\"\n",
      "    __global__ void doublify(float *a)\n",
      "    {\n",
      "      int idx = threadIdx.x + threadIdx.y*4;\n",
      "      a[idx] *= 2;\n",
      "    }\n",
      "    \"\"\")\n",
      "\n",
      "func = mod.get_function(\"doublify\")\n",
      "func(a_gpu, block=(4,4,1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Copiar el resultado del GPU al _host_:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_doubled = numpy.empty_like(a)\n",
      "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
      "print \"original array:\"\n",
      "print a\n",
      "print \"doubled with kernel:\"\n",
      "print a_doubled\n",
      "print \"doubled in python:\"\n",
      "print 2*a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "original array:\n",
        "[[-0.50270951  2.29000282  0.76188463 -1.3433814 ]\n",
        " [ 0.31768465  1.90955937  0.35726637  0.78433448]\n",
        " [-1.55883813 -1.26382732  2.17718935 -0.14682095]\n",
        " [-0.78533858  0.1791857   0.59990937  1.08285403]]\n",
        "doubled with kernel:\n",
        "[[-1.00541902  4.58000565  1.52376926 -2.68676281]\n",
        " [ 0.6353693   3.81911874  0.71453273  1.56866896]\n",
        " [-3.11767626 -2.52765465  4.3543787  -0.2936419 ]\n",
        " [-1.57067716  0.35837141  1.19981873  2.16570807]]\n",
        "doubled in python:\n",
        "[[-1.00541902  4.58000565  1.52376926 -2.68676281]\n",
        " [ 0.6353693   3.81911874  0.71453273  1.56866896]\n",
        " [-3.11767626 -2.52765465  4.3543787  -0.2936419 ]\n",
        " [-1.57067716  0.35837141  1.19981873  2.16570807]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####2.3 Segundos pasos, forma alternativa de invocar el kernel\n",
      "El kernel esta cargado en el GPU y puede invocarse con el llamado `func`, lo que var\u00eda es como se pasan par\u00e1metros:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "func(cuda.InOut(a), block=(4, 4, 1))\n",
      "print \"doubled with InOut:\"\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "doubled with InOut:\n",
        "[[-1.00541902  4.58000565  1.52376926 -2.68676281]\n",
        " [ 0.6353693   3.81911874  0.71453273  1.56866896]\n",
        " [-3.11767626 -2.52765465  4.3543787  -0.2936419 ]\n",
        " [-1.57067716  0.35837141  1.19981873  2.16570807]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O tambi\u00e9n puede usarse el m\u00e9todo `gpuarray` que automaticamente declara y asigna memoria en el dispositivo:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.gpuarray as gpuarray\n",
      "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
      "a_doubled = (2*a_gpu).get()\n",
      "\n",
      "print \"original array:\"\n",
      "print a_gpu\n",
      "print \"doubled with gpuarray:\"\n",
      "print a_doubled"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "original array:\n",
        "[[ 0.97876912 -0.0262526  -0.27445376  0.75517148]\n",
        " [-0.73505282  0.7050603   0.15917382 -0.70837629]\n",
        " [ 0.35714313 -1.13178968 -0.15013747 -0.14700417]\n",
        " [ 0.56050646  0.14032641  0.38117152 -0.37172565]]\n",
        "doubled with gpuarray:\n",
        "[[ 1.95753825 -0.05250521 -0.54890752  1.51034296]\n",
        " [-1.47010565  1.41012061  0.31834763 -1.41675258]\n",
        " [ 0.71428627 -2.26357937 -0.30027494 -0.29400834]\n",
        " [ 1.12101293  0.28065282  0.76234305 -0.7434513 ]]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estas \u00faltimas formas de invocar un kernel usando pyCUDA eliminan las abstracciones del modelo de programaci\u00f3n CUDA haciendo m\u00e1s inmediato el uso del GPU. Es importante, sin embargo, tener en mente siempre los conceptos b\u00e1sicos del modelo de programaci\u00f3n al usar pyCUDA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 135%;\n",
        "        font-size: 120%;\n",
        "        width:600px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<IPython.core.display.HTML at 0x4b5cf10>"
       ]
      }
     ],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}